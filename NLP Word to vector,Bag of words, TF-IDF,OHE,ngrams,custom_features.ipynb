{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f45d8d7e",
   "metadata": {},
   "source": [
    "What is Feature Extraction from text?\n",
    "\n",
    "Converting text to numbers is known as feature extraction.\n",
    "This is also known as text representation or text vectorization."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4acf6d34",
   "metadata": {},
   "source": [
    "Our target is convert a text into numbers such that the numbers can convey the meaning, sentiment of the text in the best possible manner"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3523f56",
   "metadata": {},
   "source": [
    "Here we will be learning these text vectrorization techniques:-\n",
    "    1. One hot encoder\n",
    "    2. Bag of Words\n",
    "    3. ngrams\n",
    "    4. TF-IDF\n",
    "    5. Custom Features\n",
    "    6. Word to Vec or Embeddings (Deep Learning topic)(For next video)\n",
    "    \n",
    " Custom Features:- Sometimes on the basis of our experience, domain knowledge etc we can build some features of our own.\n",
    " ex- How many words are present in the text, How many times a word is present in the text, Average size of each word in the text, How many vowels or consonants are used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eab9ff",
   "metadata": {},
   "source": [
    "# COMMON TERMS"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bdce5b91",
   "metadata": {},
   "source": [
    "Corpus(C)-Combination of all strings present in a column. Generally represented by C.\n",
    "       Ex- A column contains the descriptions of the movies. If we combine all the descriptions in the column then it is a            corpus.\n",
    "       \n",
    "Vocabulary(V)- Imagine our corpus contains 10 lakh words. Many words will be repeated. The unique words are known as vocabulary.\n",
    "\n",
    "Document(D)- Every individual review is a columnn.\n",
    "\n",
    "Word(W)-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df7b953",
   "metadata": {},
   "source": [
    "# BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f5893c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "38ceecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'text':['people watch campusx','campusx watch campusx','people write comment','campusx write comment'],'output':[1,1,0,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2bd4d429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campusx watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campusx write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  output\n",
       "0   people watch campusx       1\n",
       "1  campusx watch campusx       1\n",
       "2   people write comment       0\n",
       "3  campusx write comment       0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7b8471fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "147de644",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow=cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7916e8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 0)\t2\n",
      "  (2, 2)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 1)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 4)\t1\n",
      "  (3, 1)\t1\n"
     ]
    }
   ],
   "source": [
    "print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "533172d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 2, 'watch': 3, 'campusx': 0, 'write': 4, 'comment': 1}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)\n",
    "\n",
    "#number by the side of the words indicates the indices of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8f219f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bow[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "392d3ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bow[1].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5d333001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(['campusx watch and write comment']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9332493f",
   "metadata": {},
   "source": [
    "# N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d4db4c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campusx watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campusx write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  output\n",
       "0   people watch campusx       1\n",
       "1  campusx watch campusx       1\n",
       "2   people write comment       0\n",
       "3  campusx write comment       0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "740610b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(ngram_range=(2,2)) #2,2 indicates there will be bigrams only in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fe39de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow=cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f41ed44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "296b9e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people watch': 2, 'watch campusx': 4, 'campusx watch': 0, 'people write': 3, 'write comment': 5, 'campusx write': 1}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4674b5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 4, 'watch': 7, 'campusx': 0, 'people watch': 5, 'watch campusx': 8, 'campusx watch': 1, 'write': 9, 'comment': 3, 'people write': 6, 'write comment': 10, 'campusx write': 2}\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "cv1=CountVectorizer(ngram_range=(1,2)) #1,2 indicates that there will be both bigrams and unigrams in the vocabulary\n",
    "bow=cv1.fit_transform(df['text'])\n",
    "print(cv1.vocabulary_)\n",
    "print(len(cv1.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fb3824f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people watch campusx': 2, 'campusx watch campusx': 0, 'people write comment': 3, 'campusx write comment': 1}\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "cv1=CountVectorizer(ngram_range=(3,3)) #3,3 indicates that there will be trigrams in the vocabulary\n",
    "bow=cv1.fit_transform(df['text'])\n",
    "print(cv1.vocabulary_)\n",
    "print(len(cv1.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c5e15d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people watch': 4, 'watch campusx': 8, 'people watch campusx': 5, 'campusx watch': 0, 'campusx watch campusx': 1, 'people write': 6, 'write comment': 9, 'people write comment': 7, 'campusx write': 2, 'campusx write comment': 3}\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "cv1=CountVectorizer(ngram_range=(2,3)) #2,3 indicates that there will be both bigrams and trigrams in the vocabulary\n",
    "bow=cv1.fit_transform(df['text'])\n",
    "print(cv1.vocabulary_)\n",
    "print(len(cv1.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9e8aa2fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-4bb6916fdef4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcv1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#1,2 indicates that there will be both bigrams and unigrams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#here vocabulary is not forming since none of the documents contains 4 words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m         \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1218\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m   1221\u001b[0m                     \u001b[1;34m\"empty vocabulary; perhaps the documents only contain stop words\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m                 )\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "cv1=CountVectorizer(ngram_range=(4,4)) #4,4 indicates that there will be both only quadgrams in the vocabulary.\n",
    "bow=cv1.fit_transform(df['text'])\n",
    "print(cv1.vocabulary_)\n",
    "\n",
    "#here vocabulary is not forming since none of the documents contains 4 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a959a95b",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a1997f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer()\n",
    "tfidf.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6361f2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49681612, 0.        , 0.61366674, 0.61366674, 0.        ],\n",
       "       [0.8508161 , 0.        , 0.        , 0.52546357, 0.        ],\n",
       "       [0.        , 0.57735027, 0.57735027, 0.        , 0.57735027],\n",
       "       [0.49681612, 0.61366674, 0.        , 0.        , 0.61366674]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit_transform(df['text']).toarray() #It is being converted to array because tfidf.fit_transfrom returns sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3766ec20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.22314355 1.51082562 1.51082562 1.51082562 1.51082562]\n",
      "['campusx' 'comment' 'people' 'watch' 'write']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.idf_) #idf values are constant for every term\n",
    "print(tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de2c62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ba6735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
